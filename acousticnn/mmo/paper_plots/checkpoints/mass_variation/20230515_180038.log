2023-05-15 18:00:38,404 - INFO - Config:
Namespace(config='configs/implicit_transformer.yaml', dir='experiments/mass_variation', epochs=100, device='cuda', seed=0, parameter_list='configs/data.yaml', encoding='none', dir_name='mass_variation')
2023-05-15 18:00:38,405 - INFO - Config:
Munch({'optimizer': Munch({'type': 'AdamW', 'kwargs': Munch({'lr': 0.0025, 'weight_decay': 0.005, 'betas': [0.9, 0.95]})}), 'scheduler': Munch({'type': 'CosLR', 'kwargs': Munch({'epochs': 1500, 'initial_epochs': 50})}), 'model': Munch({'name': 'ImplicitTransformer', 'input_encoding': 'none', 'encoding_dim': 16, 'encoder': Munch({'embed_dim': 66, 'num_heads': 3, 'depth': 4}), 'decoder': Munch({'embed_dim': 99, 'num_heads': 3, 'depth': 3})}), 'generation_frequency': 5000, 'validation_frequency': 10, 'batch_size': 16, 'epochs': 1500, 'gradient_clip': 10})
2023-05-15 18:00:56,968 - INFO - Epoch 0 training loss = 2.816e+04
2023-05-15 18:00:57,288 - INFO - Validation loss = 1.669e+04
2023-05-15 18:00:57,289 - INFO - best model
2023-05-15 18:01:01,451 - INFO - Epoch 1 training loss = 1.453e+04
2023-05-15 18:01:05,576 - INFO - Epoch 2 training loss = 807.3
2023-05-15 18:01:09,678 - INFO - Epoch 3 training loss = 359.8
2023-05-15 18:01:13,793 - INFO - Epoch 4 training loss = 363.3
2023-05-15 18:01:17,907 - INFO - Epoch 5 training loss = 305.2
2023-05-15 18:01:22,003 - INFO - Epoch 6 training loss = 261.9
2023-05-15 18:01:26,094 - INFO - Epoch 7 training loss = 253.3
2023-05-15 18:01:30,198 - INFO - Epoch 8 training loss = 226.6
2023-05-15 18:01:34,274 - INFO - Epoch 9 training loss = 194.3
2023-05-15 18:01:38,388 - INFO - Epoch 10 training loss = 167.1
2023-05-15 18:01:38,709 - INFO - Validation loss = 202.1
2023-05-15 18:01:38,709 - INFO - best model
2023-05-15 18:01:42,876 - INFO - Epoch 11 training loss = 141.5
2023-05-15 18:01:47,024 - INFO - Epoch 12 training loss = 149.5
2023-05-15 18:01:51,113 - INFO - Epoch 13 training loss = 135.7
2023-05-15 18:01:55,208 - INFO - Epoch 14 training loss = 120.1
2023-05-15 18:01:59,311 - INFO - Epoch 15 training loss = 140.7
2023-05-15 18:02:03,417 - INFO - Epoch 16 training loss = 125.9
2023-05-15 18:02:07,527 - INFO - Epoch 17 training loss = 113.8
2023-05-15 18:02:11,640 - INFO - Epoch 18 training loss = 106.0
2023-05-15 18:02:15,771 - INFO - Epoch 19 training loss = 114.9
2023-05-15 18:02:19,923 - INFO - Epoch 20 training loss = 92.42
2023-05-15 18:02:20,241 - INFO - Validation loss = 276.5
2023-05-15 18:02:24,382 - INFO - Epoch 21 training loss = 94.26
2023-05-15 18:02:28,519 - INFO - Epoch 22 training loss = 89.03
2023-05-15 18:02:32,632 - INFO - Epoch 23 training loss = 74.58
2023-05-15 18:02:36,774 - INFO - Epoch 24 training loss = 77.91
2023-05-15 18:02:40,935 - INFO - Epoch 25 training loss = 68.96
2023-05-15 18:02:45,097 - INFO - Epoch 26 training loss = 68.81
2023-05-15 18:02:49,282 - INFO - Epoch 27 training loss = 71.06
2023-05-15 18:02:53,429 - INFO - Epoch 28 training loss = 71.84
2023-05-15 18:02:57,558 - INFO - Epoch 29 training loss = 58.92
2023-05-15 18:03:01,673 - INFO - Epoch 30 training loss = 63.75
2023-05-15 18:03:01,991 - INFO - Validation loss = 211.5
2023-05-15 18:03:06,102 - INFO - Epoch 31 training loss = 51.72
2023-05-15 18:03:10,216 - INFO - Epoch 32 training loss = 56.0
2023-05-15 18:03:14,319 - INFO - Epoch 33 training loss = 53.3
2023-05-15 18:03:18,423 - INFO - Epoch 34 training loss = 45.67
2023-05-15 18:03:22,508 - INFO - Epoch 35 training loss = 45.03
2023-05-15 18:03:26,594 - INFO - Epoch 36 training loss = 47.96
2023-05-15 18:03:30,691 - INFO - Epoch 37 training loss = 50.15
2023-05-15 18:03:34,783 - INFO - Epoch 38 training loss = 51.41
2023-05-15 18:03:38,880 - INFO - Epoch 39 training loss = 43.72
2023-05-15 18:03:42,973 - INFO - Epoch 40 training loss = 46.37
2023-05-15 18:03:43,291 - INFO - Validation loss = 233.3
2023-05-15 18:03:47,389 - INFO - Epoch 41 training loss = 41.91
2023-05-15 18:03:51,486 - INFO - Epoch 42 training loss = 40.52
2023-05-15 18:03:55,597 - INFO - Epoch 43 training loss = 43.27
2023-05-15 18:03:59,700 - INFO - Epoch 44 training loss = 39.85
2023-05-15 18:04:03,795 - INFO - Epoch 45 training loss = 40.32
2023-05-15 18:04:07,906 - INFO - Epoch 46 training loss = 38.4
2023-05-15 18:04:12,007 - INFO - Epoch 47 training loss = 34.81
2023-05-15 18:04:16,115 - INFO - Epoch 48 training loss = 32.13
2023-05-15 18:04:20,210 - INFO - Epoch 49 training loss = 35.97
2023-05-15 18:04:24,307 - INFO - Epoch 50 training loss = 32.58
2023-05-15 18:04:24,623 - INFO - Validation loss = 256.3
2023-05-15 18:04:28,717 - INFO - Epoch 51 training loss = 36.22
2023-05-15 18:04:32,816 - INFO - Epoch 52 training loss = 34.0
2023-05-15 18:04:36,914 - INFO - Epoch 53 training loss = 32.42
2023-05-15 18:04:41,023 - INFO - Epoch 54 training loss = 30.68
2023-05-15 18:04:45,132 - INFO - Epoch 55 training loss = 32.5
2023-05-15 18:04:49,243 - INFO - Epoch 56 training loss = 27.54
2023-05-15 18:04:53,356 - INFO - Epoch 57 training loss = 28.07
2023-05-15 18:04:57,453 - INFO - Epoch 58 training loss = 31.34
2023-05-15 18:05:01,546 - INFO - Epoch 59 training loss = 24.94
2023-05-15 18:05:05,651 - INFO - Epoch 60 training loss = 23.06
2023-05-15 18:05:05,970 - INFO - Validation loss = 249.8
2023-05-15 18:05:10,070 - INFO - Epoch 61 training loss = 24.14
2023-05-15 18:05:14,174 - INFO - Epoch 62 training loss = 21.19
2023-05-15 18:05:18,276 - INFO - Epoch 63 training loss = 26.32
2023-05-15 18:05:22,401 - INFO - Epoch 64 training loss = 21.77
2023-05-15 18:05:26,532 - INFO - Epoch 65 training loss = 21.61
2023-05-15 18:05:30,667 - INFO - Epoch 66 training loss = 20.74
2023-05-15 18:05:34,791 - INFO - Epoch 67 training loss = 21.09
2023-05-15 18:05:38,893 - INFO - Epoch 68 training loss = 21.56
2023-05-15 18:05:43,002 - INFO - Epoch 69 training loss = 20.46
2023-05-15 18:05:47,137 - INFO - Epoch 70 training loss = 16.21
2023-05-15 18:05:47,463 - INFO - Validation loss = 277.1
2023-05-15 18:05:51,598 - INFO - Epoch 71 training loss = 19.09
2023-05-15 18:05:55,696 - INFO - Epoch 72 training loss = 18.3
2023-05-15 18:05:59,813 - INFO - Epoch 73 training loss = 19.84
2023-05-15 18:06:03,916 - INFO - Epoch 74 training loss = 18.71
2023-05-15 18:06:08,159 - INFO - Epoch 75 training loss = 18.48
2023-05-15 18:06:12,331 - INFO - Epoch 76 training loss = 16.29
2023-05-15 18:06:16,466 - INFO - Epoch 77 training loss = 17.74
2023-05-15 18:06:20,947 - INFO - Epoch 78 training loss = 17.93
2023-05-15 18:06:25,367 - INFO - Epoch 79 training loss = 14.77
2023-05-15 18:06:29,530 - INFO - Epoch 80 training loss = 14.22
2023-05-15 18:06:29,847 - INFO - Validation loss = 275.3
