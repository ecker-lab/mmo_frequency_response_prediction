optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.001 ,
  weight_decay : 0.005,
  betas: [0.9, 0.95]
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 1000,
    initial_epochs : 101
}}

model : {
  name: "ExplicitMLP",
  input_encoding: True,
  encoding_dim: 16,
  embed_dim: 64,
  depth: 6,
  mlp_width: 256, 
  num_frequencies: 200
}

generation_frequency: 5001 #in number of epochs
validation_frequency: 10
batch_size : 128
epochs : 1000
gradient_clip: 10