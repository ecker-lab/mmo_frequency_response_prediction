optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.001,
  weight_decay : 0.005,
  betas: [0.9, 0.95]
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 500,
    initial_epochs : 25
}}

model : {
  name: "ImplicitMLP",
  input_encoding: False,
  encoding_dim: 16,
  embed_dim: 64,
  depth: 7,
  mlp_width: 256
}

generation_frequency: 5001 #in number of epochs
validation_frequency: 10
batch_size : 16
epochs : 500
gradient_clip: 10