optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.001 ,
  weight_decay : 0.005,
  betas: [0.9, 0.95]
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 1000,
    initial_epochs : 101
}}

model : {
  name: "ExplicitTransformer",
  input_encoding: False,
  encoding_dim: 16,
  num_frequencies: 200,
  encoder: {
    embed_dim: 128,
    num_heads: 4,
    depth: 6,
    },
}

generation_frequency: 5000 #in number of epochs
validation_frequency: 10
batch_size : 128
epochs : 1000
gradient_clip: 10